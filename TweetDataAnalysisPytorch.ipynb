{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TweetDataAnalysisPytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ichlMgWTOk_ZbC-Uo7bPvewUR9j_VyuT",
      "authorship_tag": "ABX9TyM0+0gcdv3brahQ2+SxiJI0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mubinui/NeuralNetworks/blob/main/TweetDataAnalysisPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Installing <b>pytorch</b></h3>"
      ],
      "metadata": {
        "id": "wsLo9sHBtEU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "hESUWtXWtCKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVq6Yi4Gy2xl",
        "outputId": "7f186341-50e3-4154-84e1-3881c2c8b309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.62.3)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchtext) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Importing necessary Libraries<h3>"
      ],
      "metadata": {
        "id": "V-lakWows5vE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP211gFOqbGr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sklearn\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()"
      ],
      "metadata": {
        "id": "U5G9WWM6O7rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> Removing emojies and url</h3>"
      ],
      "metadata": {
        "id": "TJM_6WdVtSeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "def remove_url(text): \n",
        "    url_pattern  = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    return url_pattern.sub(r'', text)\n",
        " # converting return value from list to string\n",
        "\n",
        "\n",
        "\n",
        "def clean_text(text ): \n",
        "    delete_dict = {sp_character: '' for sp_character in string.punctuation} \n",
        "    delete_dict[' '] = ' ' \n",
        "    table = str.maketrans(delete_dict)\n",
        "    text1 = text.translate(table)\n",
        "    #print('cleaned:'+text1)\n",
        "    textArr= text1.split()\n",
        "    text2 = ' '.join([w for w in textArr if ( not w.isdigit() and  ( not w.isdigit() and len(w)>2))]) \n",
        "    \n",
        "    return text2.lower()"
      ],
      "metadata": {
        "id": "rIjn_znDreoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment(sentiment):\n",
        "    if sentiment == 'positive':\n",
        "        return 2\n",
        "    elif sentiment == 'negative':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "    "
      ],
      "metadata": {
        "id": "rB6jtJBfrjWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data= pd.read_csv('/content/drive/MyDrive/Kaggle_Sentiment_data/train.csv')\n",
        "train_data.dropna(axis = 0, how ='any',inplace=True) \n",
        "train_data['Num_words_text'] = train_data['text'].apply(lambda x:len(str(x).split())) \n",
        "mask = train_data['Num_words_text'] >2\n",
        "train_data = train_data[mask]\n",
        "print('-------Train data--------')\n",
        "print(train_data['sentiment'].value_counts())\n",
        "print(len(train_data))\n",
        "print('-------------------------')\n",
        "max_train_sentence_length  = train_data['Num_words_text'].max()\n",
        "\n",
        "\n",
        "train_data['text'] = train_data['text'].apply(remove_emoji)\n",
        "train_data['text'] = train_data['text'].apply(remove_url)\n",
        "train_data['text'] = train_data['text'].apply(clean_text)\n",
        "\n",
        "train_data['label'] = train_data['sentiment'].apply(get_sentiment)\n",
        "\n",
        "test_data= pd.read_csv(\"/content/drive/MyDrive/Kaggle_Sentiment_data/test.csv\")\n",
        "test_data.dropna(axis = 0, how ='any',inplace=True) \n",
        "test_data['Num_words_text'] = test_data['text'].apply(lambda x:len(str(x).split())) \n",
        "\n",
        "max_test_sentence_length  = test_data['Num_words_text'].max()\n",
        "\n",
        "mask = test_data['Num_words_text'] >2\n",
        "test_data = test_data[mask]\n",
        "\n",
        "print('-------Test data--------')\n",
        "print(test_data['sentiment'].value_counts())\n",
        "print(len(test_data))\n",
        "print('-------------------------')\n",
        "\n",
        "test_data['text'] = test_data['text'].apply(remove_emoji)\n",
        "test_data['text'] = test_data['text'].apply(remove_url)\n",
        "test_data['text'] = test_data['text'].apply(clean_text)\n",
        "\n",
        "test_data['label'] = test_data['sentiment'].apply(get_sentiment)\n",
        "\n",
        "print('Train Max Sentence Length :'+str(max_train_sentence_length))\n",
        "print('Test Max Sentence Length :'+str(max_test_sentence_length))"
      ],
      "metadata": {
        "id": "5epqoENIrrBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f767d4c-c333-44f1-ef1e-49dc6dc450c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------Train data--------\n",
            "neutral     10704\n",
            "positive     8375\n",
            "negative     7673\n",
            "Name: sentiment, dtype: int64\n",
            "26752\n",
            "-------------------------\n",
            "-------Test data--------\n",
            "neutral     1376\n",
            "positive    1075\n",
            "negative     983\n",
            "Name: sentiment, dtype: int64\n",
            "3434\n",
            "-------------------------\n",
            "Train Max Sentence Length :33\n",
            "Test Max Sentence Length :32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head(10)"
      ],
      "metadata": {
        "id": "oDNVHucEr5yc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "2e68cd30-1048-450b-cbac-a78104ea0999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3ec0a255-c59b-4d04-b15f-a6367eaf11e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Num_words_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>have responded were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>sooo sad will miss you here san diego</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>boss bullying</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview leave alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>sons why couldnt they put them the releases al...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>28b57f3990</td>\n",
              "      <td>some shameless plugging for the best rangers f...</td>\n",
              "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6e0c6d75b1</td>\n",
              "      <td>2am feedings for the baby are fun when all smi...</td>\n",
              "      <td>fun</td>\n",
              "      <td>positive</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>e050245fbd</td>\n",
              "      <td>both you</td>\n",
              "      <td>Both of you</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>fc2cbefa9d</td>\n",
              "      <td>journey wow just became cooler hehe that possible</td>\n",
              "      <td>Wow... u just became cooler.</td>\n",
              "      <td>positive</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2339a9b08b</td>\n",
              "      <td>much love hopeful reckon the chances are minim...</td>\n",
              "      <td>as much as i love to be hopeful, i reckon the ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ec0a255-c59b-4d04-b15f-a6367eaf11e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ec0a255-c59b-4d04-b15f-a6367eaf11e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ec0a255-c59b-4d04-b15f-a6367eaf11e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        textID  ... label\n",
              "0   cb774db0d1  ...     0\n",
              "1   549e992a42  ...     1\n",
              "2   088c60f138  ...     1\n",
              "3   9642c003ef  ...     1\n",
              "4   358bd9e861  ...     1\n",
              "5   28b57f3990  ...     0\n",
              "6   6e0c6d75b1  ...     2\n",
              "8   e050245fbd  ...     0\n",
              "9   fc2cbefa9d  ...     2\n",
              "10  2339a9b08b  ...     0\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head(10)"
      ],
      "metadata": {
        "id": "2NeAvTHksBbM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "fa7c8e16-f348-45eb-c09d-f047b2570e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2d2b24f3-7f7c-43ed-a44b-878134301421\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Num_words_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>f87dea47db</td>\n",
              "      <td>last session the day</td>\n",
              "      <td>neutral</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>96d74cb729</td>\n",
              "      <td>shanghai also really exciting precisely skyscr...</td>\n",
              "      <td>positive</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eee518ae67</td>\n",
              "      <td>recession hit veronique branquinho she has qui...</td>\n",
              "      <td>negative</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33987a8ee5</td>\n",
              "      <td>like</td>\n",
              "      <td>positive</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>726e501993</td>\n",
              "      <td>thats great weee visitors</td>\n",
              "      <td>positive</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>261932614e</td>\n",
              "      <td>think everyone hates here lol</td>\n",
              "      <td>negative</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>afa11da83f</td>\n",
              "      <td>soooooo wish could but school and myspace comp...</td>\n",
              "      <td>negative</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>e64208b4ef</td>\n",
              "      <td>and within short time the last clue all them</td>\n",
              "      <td>neutral</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>37bcad24ca</td>\n",
              "      <td>what did you get day alright havent done anyth...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>24c92644a4</td>\n",
              "      <td>bike was put holdshould have known that argh t...</td>\n",
              "      <td>negative</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d2b24f3-7f7c-43ed-a44b-878134301421')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d2b24f3-7f7c-43ed-a44b-878134301421 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d2b24f3-7f7c-43ed-a44b-878134301421');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        textID  ... label\n",
              "0   f87dea47db  ...     0\n",
              "1   96d74cb729  ...     2\n",
              "2   eee518ae67  ...     1\n",
              "4   33987a8ee5  ...     2\n",
              "5   726e501993  ...     2\n",
              "6   261932614e  ...     1\n",
              "7   afa11da83f  ...     1\n",
              "8   e64208b4ef  ...     0\n",
              "9   37bcad24ca  ...     0\n",
              "10  24c92644a4  ...     1\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> Test Train Split </h3>"
      ],
      "metadata": {
        "id": "9MZE-zGVw5IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, Y_train, Y_valid= train_test_split(train_data['text'].tolist(),\\\n",
        "                                                      train_data['label'].tolist(),\\\n",
        "                                                      test_size=0.2,\\\n",
        "                                                      stratify = train_data['label'].tolist(),\\\n",
        "                                                      random_state=0)\n",
        "\n",
        "\n",
        "print('Train data len:'+str(len(X_train)))\n",
        "print('Class distribution'+str(Counter(Y_train)))\n",
        "\n",
        "\n",
        "print('Valid data len:'+str(len(X_valid)))\n",
        "print('Class distribution'+ str(Counter(Y_valid)))\n",
        "\n",
        "print('Test data len:'+str(len(test_data['text'].tolist())))\n",
        "print('Class distribution'+ str(Counter(test_data['label'].tolist())))\n",
        "\n",
        "\n",
        "train_dat =list(zip(Y_train,X_train))\n",
        "valid_dat =list(zip(Y_valid,X_valid))\n",
        "test_dat=list(zip(test_data['label'].tolist(),test_data['text'].tolist()))"
      ],
      "metadata": {
        "id": "24UO3aXUsOg8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b15c96f-a6e1-4bdd-fd01-43f28ad97769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data len:21401\n",
            "Class distributionCounter({0: 8563, 2: 6700, 1: 6138})\n",
            "Valid data len:5351\n",
            "Class distributionCounter({0: 2141, 2: 1675, 1: 1535})\n",
            "Test data len:3434\n",
            "Class distributionCounter({0: 1376, 2: 1075, 1: 983})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "5RebrFNusPvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "train_iter = train_dat\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "avPcfhoEsaQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x) "
      ],
      "metadata": {
        "id": "Y1rr0TlUsg9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline('here is the an example')"
      ],
      "metadata": {
        "id": "6xsoYKjsskLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b3ede5e-5110-4f12-dce0-8a93986eecc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[62, 0, 1, 0, 12881]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_pipeline('1')"
      ],
      "metadata": {
        "id": "uouD8pfbsnBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd52e45-ac72-40f1-e781-5187171d8a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_label, _text) in batch:\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
        "\n",
        "#train_iter =train_dat\n",
        "#dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "K0wsaovGssqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc1 = nn.Linear(embed_dim,64)\n",
        "        self.fc2 = nn.Linear(64,16)\n",
        "        self.fc3 = nn.Linear(16, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc1.bias.data.zero_()\n",
        "        self.fc2.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc2.bias.data.zero_()\n",
        "        self.fc3.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc3.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        x = F.relu(self.fc1(embedded))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "CynJA5JoswoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter1 = train_dat\n",
        "num_class = len(set([label for (label, text) in train_iter1]))\n",
        "print(num_class)\n",
        "vocab_size = len(vocab)\n",
        "emsize = 128\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ],
      "metadata": {
        "id": "bZxqqOQItjyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b908c582-bb58-4bfb-c221-f6bbf0ab3b1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predited_label = model(text, offsets)\n",
        "        loss = criterion(predited_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc/total_count))\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predited_label = model(text, offsets)\n",
        "            loss = criterion(predited_label, label)\n",
        "            writer.add_scalar(\"Loss/train\", loss, idx)\n",
        "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count\n",
        "    writer.flush()"
      ],
      "metadata": {
        "id": "Be9zzMUttk7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><b> Training the model</b></h3>"
      ],
      "metadata": {
        "id": "8I9ZL82X07F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "# Hyperparameters\n",
        "EPOCHS = 100 # epoch\n",
        "LR = 10 # learning rate\n",
        "BATCH_SIZE = 16 # batch size for training\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "\n",
        "train_iter2 = train_dat\n",
        "test_iter2 =test_dat \n",
        "valid_iter2= valid_dat\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(train_iter2, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(valid_iter2, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_iter2, batch_size=BATCH_SIZE,\n",
        "                             shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)"
      ],
      "metadata": {
        "id": "ZH7GAdbDtvX4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba8dd1e8-2bd5-48e3-fad2-a5213a353aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 1338 batches | accuracy    0.439\n",
            "| epoch   1 |  1000/ 1338 batches | accuracy    0.535\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time:  3.40s | valid accuracy    0.564 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 1338 batches | accuracy    0.610\n",
            "| epoch   2 |  1000/ 1338 batches | accuracy    0.619\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time:  3.27s | valid accuracy    0.490 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 1338 batches | accuracy    0.708\n",
            "| epoch   3 |  1000/ 1338 batches | accuracy    0.719\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time:  3.27s | valid accuracy    0.667 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 1338 batches | accuracy    0.739\n",
            "| epoch   4 |  1000/ 1338 batches | accuracy    0.737\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time:  3.22s | valid accuracy    0.676 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 1338 batches | accuracy    0.756\n",
            "| epoch   5 |  1000/ 1338 batches | accuracy    0.755\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time:  3.31s | valid accuracy    0.675 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 1338 batches | accuracy    0.773\n",
            "| epoch   6 |  1000/ 1338 batches | accuracy    0.775\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time:  3.31s | valid accuracy    0.676 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 1338 batches | accuracy    0.782\n",
            "| epoch   7 |  1000/ 1338 batches | accuracy    0.768\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time:  3.31s | valid accuracy    0.675 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 1338 batches | accuracy    0.777\n",
            "| epoch   8 |  1000/ 1338 batches | accuracy    0.774\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time:  3.28s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 1338 batches | accuracy    0.776\n",
            "| epoch   9 |  1000/ 1338 batches | accuracy    0.779\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time:  3.24s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 1338 batches | accuracy    0.773\n",
            "| epoch  10 |  1000/ 1338 batches | accuracy    0.776\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time:  3.32s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  11 |   500/ 1338 batches | accuracy    0.777\n",
            "| epoch  11 |  1000/ 1338 batches | accuracy    0.774\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  11 | time:  3.42s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  12 |   500/ 1338 batches | accuracy    0.787\n",
            "| epoch  12 |  1000/ 1338 batches | accuracy    0.771\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  12 | time:  3.24s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  13 |   500/ 1338 batches | accuracy    0.772\n",
            "| epoch  13 |  1000/ 1338 batches | accuracy    0.785\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  13 | time:  3.30s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  14 |   500/ 1338 batches | accuracy    0.775\n",
            "| epoch  14 |  1000/ 1338 batches | accuracy    0.777\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  14 | time:  3.43s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  15 |   500/ 1338 batches | accuracy    0.776\n",
            "| epoch  15 |  1000/ 1338 batches | accuracy    0.781\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  15 | time:  3.35s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  16 |   500/ 1338 batches | accuracy    0.778\n",
            "| epoch  16 |  1000/ 1338 batches | accuracy    0.774\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  16 | time:  3.37s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  17 |   500/ 1338 batches | accuracy    0.778\n",
            "| epoch  17 |  1000/ 1338 batches | accuracy    0.777\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  17 | time:  3.41s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  18 |   500/ 1338 batches | accuracy    0.775\n",
            "| epoch  18 |  1000/ 1338 batches | accuracy    0.768\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  18 | time:  3.30s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  19 |   500/ 1338 batches | accuracy    0.779\n",
            "| epoch  19 |  1000/ 1338 batches | accuracy    0.777\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  19 | time:  3.40s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  20 |   500/ 1338 batches | accuracy    0.776\n",
            "| epoch  20 |  1000/ 1338 batches | accuracy    0.778\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  20 | time:  3.37s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  21 |   500/ 1338 batches | accuracy    0.769\n",
            "| epoch  21 |  1000/ 1338 batches | accuracy    0.791\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  21 | time:  3.61s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  22 |   500/ 1338 batches | accuracy    0.780\n",
            "| epoch  22 |  1000/ 1338 batches | accuracy    0.775\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  22 | time:  3.40s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  23 |   500/ 1338 batches | accuracy    0.773\n",
            "| epoch  23 |  1000/ 1338 batches | accuracy    0.783\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  23 | time:  3.34s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  24 |   500/ 1338 batches | accuracy    0.779\n",
            "| epoch  24 |  1000/ 1338 batches | accuracy    0.777\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  24 | time:  3.39s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  25 |   500/ 1338 batches | accuracy    0.775\n",
            "| epoch  25 |  1000/ 1338 batches | accuracy    0.779\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  25 | time:  3.45s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  26 |   500/ 1338 batches | accuracy    0.777\n",
            "| epoch  26 |  1000/ 1338 batches | accuracy    0.779\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  26 | time:  3.36s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  27 |   500/ 1338 batches | accuracy    0.778\n",
            "| epoch  27 |  1000/ 1338 batches | accuracy    0.778\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  27 | time:  3.49s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  28 |   500/ 1338 batches | accuracy    0.780\n",
            "| epoch  28 |  1000/ 1338 batches | accuracy    0.775\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  28 | time:  3.42s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  29 |   500/ 1338 batches | accuracy    0.777\n",
            "| epoch  29 |  1000/ 1338 batches | accuracy    0.779\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  29 | time:  3.33s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  30 |   500/ 1338 batches | accuracy    0.778\n",
            "| epoch  30 |  1000/ 1338 batches | accuracy    0.776\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  30 | time:  3.31s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  31 |   500/ 1338 batches | accuracy    0.772\n",
            "| epoch  31 |  1000/ 1338 batches | accuracy    0.773\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  31 | time:  3.34s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  32 |   500/ 1338 batches | accuracy    0.777\n",
            "| epoch  32 |  1000/ 1338 batches | accuracy    0.776\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  32 | time:  3.22s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  33 |   500/ 1338 batches | accuracy    0.777\n",
            "| epoch  33 |  1000/ 1338 batches | accuracy    0.770\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  33 | time:  3.29s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  34 |   500/ 1338 batches | accuracy    0.779\n",
            "| epoch  34 |  1000/ 1338 batches | accuracy    0.775\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  34 | time:  3.31s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  35 |   500/ 1338 batches | accuracy    0.771\n",
            "| epoch  35 |  1000/ 1338 batches | accuracy    0.778\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  35 | time:  3.35s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  36 |   500/ 1338 batches | accuracy    0.777\n",
            "| epoch  36 |  1000/ 1338 batches | accuracy    0.772\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  36 | time:  3.38s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  37 |   500/ 1338 batches | accuracy    0.782\n",
            "| epoch  37 |  1000/ 1338 batches | accuracy    0.777\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  37 | time:  3.36s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  38 |   500/ 1338 batches | accuracy    0.778\n",
            "| epoch  38 |  1000/ 1338 batches | accuracy    0.775\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  38 | time:  3.41s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  39 |   500/ 1338 batches | accuracy    0.781\n",
            "| epoch  39 |  1000/ 1338 batches | accuracy    0.778\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  39 | time:  3.44s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  40 |   500/ 1338 batches | accuracy    0.777\n",
            "| epoch  40 |  1000/ 1338 batches | accuracy    0.770\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  40 | time:  3.34s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  41 |   500/ 1338 batches | accuracy    0.777\n",
            "| epoch  41 |  1000/ 1338 batches | accuracy    0.773\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  41 | time:  3.38s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  42 |   500/ 1338 batches | accuracy    0.776\n",
            "| epoch  42 |  1000/ 1338 batches | accuracy    0.782\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  42 | time:  3.29s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  43 |   500/ 1338 batches | accuracy    0.779\n",
            "| epoch  43 |  1000/ 1338 batches | accuracy    0.777\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  43 | time:  3.27s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  44 |   500/ 1338 batches | accuracy    0.776\n",
            "| epoch  44 |  1000/ 1338 batches | accuracy    0.780\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  44 | time:  3.28s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  45 |   500/ 1338 batches | accuracy    0.776\n",
            "| epoch  45 |  1000/ 1338 batches | accuracy    0.778\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  45 | time:  3.32s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  46 |   500/ 1338 batches | accuracy    0.777\n",
            "| epoch  46 |  1000/ 1338 batches | accuracy    0.774\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  46 | time:  3.59s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  47 |   500/ 1338 batches | accuracy    0.782\n",
            "| epoch  47 |  1000/ 1338 batches | accuracy    0.777\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  47 | time:  3.54s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  48 |   500/ 1338 batches | accuracy    0.772\n",
            "| epoch  48 |  1000/ 1338 batches | accuracy    0.777\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  48 | time:  3.68s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  49 |   500/ 1338 batches | accuracy    0.778\n",
            "| epoch  49 |  1000/ 1338 batches | accuracy    0.774\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  49 | time:  3.68s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  50 |   500/ 1338 batches | accuracy    0.776\n",
            "| epoch  50 |  1000/ 1338 batches | accuracy    0.776\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  50 | time:  3.55s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  51 |   500/ 1338 batches | accuracy    0.778\n",
            "| epoch  51 |  1000/ 1338 batches | accuracy    0.778\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  51 | time:  3.63s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  52 |   500/ 1338 batches | accuracy    0.777\n",
            "| epoch  52 |  1000/ 1338 batches | accuracy    0.773\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  52 | time:  3.64s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  53 |   500/ 1338 batches | accuracy    0.776\n",
            "| epoch  53 |  1000/ 1338 batches | accuracy    0.777\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  53 | time:  3.67s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  54 |   500/ 1338 batches | accuracy    0.774\n",
            "| epoch  54 |  1000/ 1338 batches | accuracy    0.780\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  54 | time:  3.35s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  55 |   500/ 1338 batches | accuracy    0.774\n",
            "| epoch  55 |  1000/ 1338 batches | accuracy    0.776\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  55 | time:  3.41s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  56 |   500/ 1338 batches | accuracy    0.781\n",
            "| epoch  56 |  1000/ 1338 batches | accuracy    0.773\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  56 | time:  3.44s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  57 |   500/ 1338 batches | accuracy    0.768\n",
            "| epoch  57 |  1000/ 1338 batches | accuracy    0.775\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  57 | time:  3.30s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  58 |   500/ 1338 batches | accuracy    0.771\n",
            "| epoch  58 |  1000/ 1338 batches | accuracy    0.781\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  58 | time:  3.41s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  59 |   500/ 1338 batches | accuracy    0.779\n",
            "| epoch  59 |  1000/ 1338 batches | accuracy    0.774\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  59 | time:  3.36s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  60 |   500/ 1338 batches | accuracy    0.781\n",
            "| epoch  60 |  1000/ 1338 batches | accuracy    0.768\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  60 | time:  3.28s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  61 |   500/ 1338 batches | accuracy    0.775\n",
            "| epoch  61 |  1000/ 1338 batches | accuracy    0.778\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  61 | time:  3.33s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  62 |   500/ 1338 batches | accuracy    0.775\n",
            "| epoch  62 |  1000/ 1338 batches | accuracy    0.776\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  62 | time:  3.46s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  63 |   500/ 1338 batches | accuracy    0.776\n",
            "| epoch  63 |  1000/ 1338 batches | accuracy    0.773\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  63 | time:  3.42s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  64 |   500/ 1338 batches | accuracy    0.778\n",
            "| epoch  64 |  1000/ 1338 batches | accuracy    0.774\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  64 | time:  3.27s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  65 |   500/ 1338 batches | accuracy    0.773\n",
            "| epoch  65 |  1000/ 1338 batches | accuracy    0.783\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  65 | time:  3.26s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  66 |   500/ 1338 batches | accuracy    0.775\n",
            "| epoch  66 |  1000/ 1338 batches | accuracy    0.776\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  66 | time:  3.30s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  67 |   500/ 1338 batches | accuracy    0.773\n",
            "| epoch  67 |  1000/ 1338 batches | accuracy    0.773\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  67 | time:  3.35s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  68 |   500/ 1338 batches | accuracy    0.778\n",
            "| epoch  68 |  1000/ 1338 batches | accuracy    0.776\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  68 | time:  3.31s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  69 |   500/ 1338 batches | accuracy    0.779\n",
            "| epoch  69 |  1000/ 1338 batches | accuracy    0.778\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  69 | time:  3.30s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  70 |   500/ 1338 batches | accuracy    0.777\n",
            "| epoch  70 |  1000/ 1338 batches | accuracy    0.778\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  70 | time:  3.34s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  71 |   500/ 1338 batches | accuracy    0.780\n",
            "| epoch  71 |  1000/ 1338 batches | accuracy    0.771\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  71 | time:  3.29s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  72 |   500/ 1338 batches | accuracy    0.774\n",
            "| epoch  72 |  1000/ 1338 batches | accuracy    0.779\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  72 | time:  3.26s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  73 |   500/ 1338 batches | accuracy    0.779\n",
            "| epoch  73 |  1000/ 1338 batches | accuracy    0.777\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  73 | time:  3.21s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  74 |   500/ 1338 batches | accuracy    0.770\n",
            "| epoch  74 |  1000/ 1338 batches | accuracy    0.780\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  74 | time:  3.23s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  75 |   500/ 1338 batches | accuracy    0.776\n",
            "| epoch  75 |  1000/ 1338 batches | accuracy    0.775\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  75 | time:  3.24s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  76 |   500/ 1338 batches | accuracy    0.776\n",
            "| epoch  76 |  1000/ 1338 batches | accuracy    0.778\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  76 | time:  3.26s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  77 |   500/ 1338 batches | accuracy    0.779\n",
            "| epoch  77 |  1000/ 1338 batches | accuracy    0.775\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  77 | time:  3.32s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  78 |   500/ 1338 batches | accuracy    0.776\n",
            "| epoch  78 |  1000/ 1338 batches | accuracy    0.785\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  78 | time:  3.32s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  79 |   500/ 1338 batches | accuracy    0.770\n",
            "| epoch  79 |  1000/ 1338 batches | accuracy    0.779\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  79 | time:  3.30s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  80 |   500/ 1338 batches | accuracy    0.783\n",
            "| epoch  80 |  1000/ 1338 batches | accuracy    0.768\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  80 | time:  3.32s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  81 |   500/ 1338 batches | accuracy    0.782\n",
            "| epoch  81 |  1000/ 1338 batches | accuracy    0.772\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  81 | time:  3.33s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  82 |   500/ 1338 batches | accuracy    0.775\n",
            "| epoch  82 |  1000/ 1338 batches | accuracy    0.774\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  82 | time:  3.40s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  83 |   500/ 1338 batches | accuracy    0.780\n",
            "| epoch  83 |  1000/ 1338 batches | accuracy    0.772\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  83 | time:  3.37s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  84 |   500/ 1338 batches | accuracy    0.766\n",
            "| epoch  84 |  1000/ 1338 batches | accuracy    0.785\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  84 | time:  3.31s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  85 |   500/ 1338 batches | accuracy    0.779\n",
            "| epoch  85 |  1000/ 1338 batches | accuracy    0.777\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  85 | time:  3.37s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  86 |   500/ 1338 batches | accuracy    0.777\n",
            "| epoch  86 |  1000/ 1338 batches | accuracy    0.779\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  86 | time:  3.35s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  87 |   500/ 1338 batches | accuracy    0.777\n",
            "| epoch  87 |  1000/ 1338 batches | accuracy    0.778\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  87 | time:  3.29s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  88 |   500/ 1338 batches | accuracy    0.773\n",
            "| epoch  88 |  1000/ 1338 batches | accuracy    0.776\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  88 | time:  3.27s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  89 |   500/ 1338 batches | accuracy    0.776\n",
            "| epoch  89 |  1000/ 1338 batches | accuracy    0.771\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  89 | time:  3.26s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  90 |   500/ 1338 batches | accuracy    0.773\n",
            "| epoch  90 |  1000/ 1338 batches | accuracy    0.778\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  90 | time:  3.34s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  91 |   500/ 1338 batches | accuracy    0.776\n",
            "| epoch  91 |  1000/ 1338 batches | accuracy    0.777\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  91 | time:  3.28s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  92 |   500/ 1338 batches | accuracy    0.773\n",
            "| epoch  92 |  1000/ 1338 batches | accuracy    0.778\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  92 | time:  3.26s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  93 |   500/ 1338 batches | accuracy    0.776\n",
            "| epoch  93 |  1000/ 1338 batches | accuracy    0.775\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  93 | time:  3.23s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  94 |   500/ 1338 batches | accuracy    0.773\n",
            "| epoch  94 |  1000/ 1338 batches | accuracy    0.782\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  94 | time:  3.22s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  95 |   500/ 1338 batches | accuracy    0.786\n",
            "| epoch  95 |  1000/ 1338 batches | accuracy    0.771\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  95 | time:  3.30s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  96 |   500/ 1338 batches | accuracy    0.775\n",
            "| epoch  96 |  1000/ 1338 batches | accuracy    0.776\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  96 | time:  3.35s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  97 |   500/ 1338 batches | accuracy    0.775\n",
            "| epoch  97 |  1000/ 1338 batches | accuracy    0.774\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  97 | time:  3.32s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  98 |   500/ 1338 batches | accuracy    0.772\n",
            "| epoch  98 |  1000/ 1338 batches | accuracy    0.778\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  98 | time:  3.40s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch  99 |   500/ 1338 batches | accuracy    0.780\n",
            "| epoch  99 |  1000/ 1338 batches | accuracy    0.773\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  99 | time:  3.42s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n",
            "| epoch 100 |   500/ 1338 batches | accuracy    0.774\n",
            "| epoch 100 |  1000/ 1338 batches | accuracy    0.779\n",
            "-----------------------------------------------------------\n",
            "| end of epoch 100 | time:  3.32s | valid accuracy    0.677 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "writer.close()"
      ],
      "metadata": {
        "id": "kK792n6tPtjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4hx_uoaPvnm",
        "outputId": "2cebfc71-e42b-4874-f5a6-e842ef1fdae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " tensorboard dev upload --logdir runs \\\n",
        "--name \"My latest experiment\" \\ # optional\n",
        "--description \"Simple comparison of several hyperparameters\" # optional"
      ],
      "metadata": {
        "id": "nZp-D54ZQBnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Accuracy Checking</h3> "
      ],
      "metadata": {
        "id": "-y9WdmWn1I8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Checking the results of test dataset.')\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print('test accuracy {:8.3f}'.format(accu_test))"
      ],
      "metadata": {
        "id": "VSkgxuvHtxaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Testing the data<h3> "
      ],
      "metadata": {
        "id": "ViZFfDnM1VIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_label = {2:\"Positive\",\n",
        "                   1: \"Negative\",\n",
        "                   0: \"Neutral\"\n",
        "                  }\n",
        "\n",
        "def predict(text, text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() \n",
        "ex_text_str = \"Let me die\"\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "print(\"This is a %s tweet\" %sentiment_label[predict(ex_text_str, text_pipeline)])"
      ],
      "metadata": {
        "id": "ZDvgKXTDt9RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_label = {2:\"Positive\",\n",
        "                   1: \"Negative\",\n",
        "                   0: \"Neutral\"\n",
        "                  }\n",
        "\n",
        "def predict(text, text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() \n",
        "ex_text_str = \"Learn to be happy \"\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "print(\"This is a %s tweet\" %sentiment_label[predict(ex_text_str, text_pipeline)])"
      ],
      "metadata": {
        "id": "VzVqtX6N8Bux"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}